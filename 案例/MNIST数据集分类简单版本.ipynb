{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#载入数据\n",
    "mnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Testing accuracy 0.8283\n",
      "Iteration 1, Testing accuracy 0.8947\n",
      "Iteration 2, Testing accuracy 0.9014\n",
      "Iteration 3, Testing accuracy 0.9058\n",
      "Iteration 4, Testing accuracy 0.9081\n",
      "Iteration 5, Testing accuracy 0.9108\n",
      "Iteration 6, Testing accuracy 0.9125\n",
      "Iteration 7, Testing accuracy 0.9146\n",
      "Iteration 8, Testing accuracy 0.9155\n",
      "Iteration 9, Testing accuracy 0.9171\n",
      "Iteration 10, Testing accuracy 0.9181\n",
      "Iteration 11, Testing accuracy 0.9183\n",
      "Iteration 12, Testing accuracy 0.9187\n",
      "Iteration 13, Testing accuracy 0.9207\n",
      "Iteration 14, Testing accuracy 0.9202\n",
      "Iteration 15, Testing accuracy 0.9215\n",
      "Iteration 16, Testing accuracy 0.9213\n",
      "Iteration 17, Testing accuracy 0.9206\n",
      "Iteration 18, Testing accuracy 0.921\n",
      "Iteration 19, Testing accuracy 0.9219\n",
      "Iteration 20, Testing accuracy 0.9215\n"
     ]
    }
   ],
   "source": [
    "#每个批次的大小\n",
    "batch_size=100\n",
    "#计算一共多少批次\n",
    "n_batch=mnist.train.num_examples//batch_size\n",
    "#定义两个placeholder\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简答的神经网络\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([10]))\n",
    "prediction=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "\n",
    "#定义二次代价函数\n",
    "# loss=tf.reduce_mean(tf.square(y-prediction))\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "     #argmax返回一维张量中最大的值所在的位置 \n",
    "#准确率\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,\n",
    "                                         y:mnist.test.labels})\n",
    "        print(\"Iteration \"+str(epoch)+\", Testing accuracy \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二次代价函数\n",
    "\n",
    "Iteration 0, Testing accuracy 0.8323\n",
    "Iteration 1, Testing accuracy 0.8709\n",
    "Iteration 2, Testing accuracy 0.8811\n",
    "Iteration 3, Testing accuracy 0.8878\n",
    "Iteration 4, Testing accuracy 0.8937\n",
    "Iteration 5, Testing accuracy 0.8976\n",
    "Iteration 6, Testing accuracy 0.8999\n",
    "Iteration 7, Testing accuracy 0.9029\n",
    "Iteration 8, Testing accuracy 0.9037\n",
    "Iteration 9, Testing accuracy 0.9053\n",
    "Iteration 10, Testing accuracy 0.9058\n",
    "Iteration 11, Testing accuracy 0.9067\n",
    "Iteration 12, Testing accuracy 0.9075\n",
    "Iteration 13, Testing accuracy 0.9093\n",
    "Iteration 14, Testing accuracy 0.9097\n",
    "Iteration 15, Testing accuracy 0.9112\n",
    "Iteration 16, Testing accuracy 0.9113\n",
    "Iteration 17, Testing accuracy 0.9125\n",
    "Iteration 18, Testing accuracy 0.913\n",
    "Iteration 19, Testing accuracy 0.9133\n",
    "Iteration 20, Testing accuracy 0.9141\n",
    "\n",
    "#交叉熵\n",
    "Iteration 0, Testing accuracy 0.8283\n",
    "Iteration 1, Testing accuracy 0.8947\n",
    "Iteration 2, Testing accuracy 0.9014\n",
    "Iteration 3, Testing accuracy 0.9058\n",
    "Iteration 4, Testing accuracy 0.9081\n",
    "Iteration 5, Testing accuracy 0.9108\n",
    "Iteration 6, Testing accuracy 0.9125\n",
    "Iteration 7, Testing accuracy 0.9146\n",
    "Iteration 8, Testing accuracy 0.9155\n",
    "Iteration 9, Testing accuracy 0.9171\n",
    "Iteration 10, Testing accuracy 0.9181\n",
    "Iteration 11, Testing accuracy 0.9183\n",
    "Iteration 12, Testing accuracy 0.9187\n",
    "Iteration 13, Testing accuracy 0.9207\n",
    "Iteration 14, Testing accuracy 0.9202\n",
    "Iteration 15, Testing accuracy 0.9215\n",
    "Iteration 16, Testing accuracy 0.9213\n",
    "Iteration 17, Testing accuracy 0.9206\n",
    "Iteration 18, Testing accuracy 0.921\n",
    "Iteration 19, Testing accuracy 0.9219\n",
    "Iteration 20, Testing accuracy 0.9215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
