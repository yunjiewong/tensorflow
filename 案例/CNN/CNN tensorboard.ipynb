{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Testing accuracy 0.0907, Training accuracy 0.0844\n",
      "Iteration 100, Testing accuracy 0.4985, Training accuracy 0.5046\n",
      "Iteration 200, Testing accuracy 0.7465, Training accuracy 0.7442\n",
      "Iteration 300, Testing accuracy 0.8218, Training accuracy 0.8151\n",
      "Iteration 400, Testing accuracy 0.8715, Training accuracy 0.8649\n",
      "Iteration 500, Testing accuracy 0.9354, Training accuracy 0.9324\n",
      "Iteration 600, Testing accuracy 0.9468, Training accuracy 0.9451\n",
      "Iteration 700, Testing accuracy 0.9504, Training accuracy 0.9514\n",
      "Iteration 800, Testing accuracy 0.9559, Training accuracy 0.9575\n",
      "Iteration 900, Testing accuracy 0.9602, Training accuracy 0.96\n",
      "Iteration 1000, Testing accuracy 0.9629, Training accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "n_batch=mnist.train.num_examples//batch_size\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean=tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean) \n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev', stddev) \n",
    "        tf.summary.scalar('max',tf.reduce_max(var)) \n",
    "        tf.summary.scalar('min',tf.reduce_min(var)) \n",
    "        tf.summary.histogram('histogram',var)\n",
    "            \n",
    "def weight_variable(shape):\n",
    "    initial=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x_input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y_input')\n",
    "    with tf.name_scope('x_image'):\n",
    "        x_image=tf.reshape(x,[-1,28,28,1],name='x_image')\n",
    "\n",
    "with tf.name_scope('Conv1'):\n",
    "    with tf.name_scope('W_conv1'):\n",
    "        W_conv1=weight_variable([5,5,1,32])\n",
    "    with tf.name_scope('b_conv1'):\n",
    "        b_conv1=bias_variable([32])\n",
    "    with tf.name_scope('conv2d_1'):\n",
    "        conv2d_1=conv2d(x_image,W_conv1)+b_conv1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv1=tf.nn.relu(conv2d_1)\n",
    "    with tf.name_scope('h_pool1'):\n",
    "        h_pool1=max_pool_2x2(h_conv1)\n",
    "\n",
    "with tf.name_scope('Conv2'):\n",
    "    with tf.name_scope('W_conv2'):\n",
    "        W_conv2=weight_variable([5,5,32,64])\n",
    "    with tf.name_scope('b_conv2'):\n",
    "        b_conv2=bias_variable([64])\n",
    "    with tf.name_scope('conv2d_2'):\n",
    "        conv2d_2=conv2d(h_pool1,W_conv2)+b_conv2\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv2=tf.nn.relu(conv2d_2)\n",
    "    with tf.name_scope('h_pool2'):\n",
    "        h_pool2=max_pool_2x2(h_conv2)\n",
    "\n",
    "with tf.name_scope('fcl'):\n",
    "    with tf.name_scope('W_fcl'):\n",
    "        W_fcl=weight_variable([7*7*64,1024])\n",
    "    with tf.name_scope('b_fcl'):\n",
    "        b_fcl=bias_variable([1024])\n",
    "    with tf.name_scope('h_pool2_flat'):\n",
    "        h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b=tf.matmul(h_pool2_flat,W_fcl)+b_fcl\n",
    "    with tf.name_scope('relu'):\n",
    "        h_fcl=tf.nn.relu(wx_plus_b)\n",
    "    with tf.name_scope('keep_prob'):\n",
    "        keep_prob=tf.placeholder(tf.float32)\n",
    "    with tf.name_scope('h_fcl_drop'):\n",
    "        h_fcl_drop=tf.nn.dropout(h_fcl,keep_prob)\n",
    "\n",
    "with tf.name_scope('fc_2'):\n",
    "    with tf.name_scope('W_fc2'):\n",
    "        W_fc2=weight_variable([1024,10])\n",
    "    with tf.name_scope('b_fc2'):\n",
    "        b_fc2=bias_variable([10])\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b=tf.matmul(h_fcl_drop,W_fc2)+b_fc2\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction=tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "    tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "with tf.name_scope('train'):\n",
    "    train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "merged= tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer=tf.summary.FileWriter('log/train',sess.graph)\n",
    "    test_writer=tf.summary.FileWriter('log/test',sess.graph)\n",
    "    \n",
    "    for i in range(1001):\n",
    "        batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.5})\n",
    "        summary=sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        train_writer.add_summary(summary,i)\n",
    "        \n",
    "        batch_xs,batch_ys=mnist.test.next_batch(batch_size)\n",
    "        summary=sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        test_writer.add_summary(summary,i)\n",
    "        \n",
    "        if i%100==0:\n",
    "            test_acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "            train_acc=sess.run(accuracy,feed_dict={x:mnist.train.images[:10000],y:mnist.train.labels[:10000],keep_prob:1.0})\n",
    "            print(\"Iteration \"+str(i)+\", Testing accuracy \"+str(test_acc)+\", Training accuracy \"+str(train_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
